{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Code by NARESHSARATHY S, SRUTHI KRISHNA GAJULA, AADHYA ENLLAWAR, PRERNA PATHAK"
      ],
      "metadata": {
        "id": "Q0HJhjQgn_A2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrKBCOL4n1Oc",
        "outputId": "af05b578-5da6-41ef-be7f-dbe5a8e78c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.5-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/129.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.5/129.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-core (from keras_tuner)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_tuner) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_tuner) (13.6.0)\n",
            "Collecting namex (from keras-core->keras_tuner)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_tuner) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_tuner) (0.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_tuner) (0.1.2)\n",
            "Installing collected packages: namex, kt-legacy, keras-core, keras_tuner\n",
            "Successfully installed keras-core-0.1.7 keras_tuner-1.4.5 kt-legacy-1.0.5 namex-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras_tuner\n",
        "from keras_tuner import RandomSearch\n",
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45TL0M2xn55a",
        "outputId": "3a2bb1af-5af3-47fa-e098-b6803ee6c630"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('river-quality-stations.csv')\n",
        "df.head()\n",
        "\n",
        "#displaying descriptive statistics\n",
        "descriptive_statistics=df.describe()\n",
        "print(descriptive_statistics)\n",
        "\n",
        "#checking for null values\n",
        "null_val=df.isnull().sum()\n",
        "print(\"Null values in data frame:\\n\")\n",
        "print(null_val)\n",
        "#finding the data type of the column\n",
        "data_type=df.dtypes\n",
        "print(\"\\nData type of the data frame:\\n\")\n",
        "print(data_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEMwtOrHoC_d",
        "outputId": "05bf1315-b31c-4ee3-fda1-247f53b02bbd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                id          NH4         BSK5    Suspended           O2  \\\n",
            "count  2861.000000  2858.000000  2860.000000  2845.000000  2858.000000   \n",
            "mean     12.397064     0.758734     4.316182    12.931905     9.508902   \n",
            "std       6.084226     2.486247     2.973997    16.543097     4.428260   \n",
            "min       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
            "25%       8.000000     0.080000     2.160000     6.000000     7.092500   \n",
            "50%      14.000000     0.220000     3.800000    10.000000     8.995000   \n",
            "75%      16.000000     0.500000     5.800000    15.000000    11.520000   \n",
            "max      22.000000    39.427000    50.900000   595.000000    90.000000   \n",
            "\n",
            "               NO3          NO2          SO4          PO4           CL  \n",
            "count  2860.000000  2858.000000  2812.000000  2833.000000  2812.000000  \n",
            "mean      4.316846     0.246128    59.362313     0.418626    93.731991  \n",
            "std       6.881188     2.182777    96.582641     0.771326   394.512184  \n",
            "min       0.000000     0.000000     0.000000     0.000000     0.020000  \n",
            "25%       1.390000     0.030000    27.052500     0.130000    26.800000  \n",
            "50%       2.800000     0.059000    37.800000     0.270000    33.900000  \n",
            "75%       5.582500     0.125750    64.640000     0.470000    45.607500  \n",
            "max     133.400000   109.000000  3573.400000    13.879000  5615.280000  \n",
            "Null values in data frame:\n",
            "\n",
            "id            0\n",
            "date          0\n",
            "NH4           3\n",
            "BSK5          1\n",
            "Suspended    16\n",
            "O2            3\n",
            "NO3           1\n",
            "NO2           3\n",
            "SO4          49\n",
            "PO4          28\n",
            "CL           49\n",
            "dtype: int64\n",
            "\n",
            "Data type of the data frame:\n",
            "\n",
            "id             int64\n",
            "date          object\n",
            "NH4          float64\n",
            "BSK5         float64\n",
            "Suspended    float64\n",
            "O2           float64\n",
            "NO3          float64\n",
            "NO2          float64\n",
            "SO4          float64\n",
            "PO4          float64\n",
            "CL           float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['NH4'].fillna(df['NH4'].mean(),inplace=True)\n",
        "df['BSK5'].fillna(df['BSK5'].mean(),inplace=True)\n",
        "df['Suspended'].fillna(df['Suspended'].mean(),inplace=True)\n",
        "df['O2'].fillna(df['O2'].mean(), inplace=True)\n",
        "df['NO3'].fillna(df['NO3'].mean(),inplace=True)\n",
        "df['NO2'].fillna(df['NO2'].mean(),inplace=True)\n",
        "df['SO4'].fillna(df['SO4'].mean(),inplace=True)\n",
        "df['PO4'].fillna(df['PO4'].mean(), inplace=True)\n",
        "df['CL'].fillna(df['CL'].mean(), inplace=True)\n",
        "\n",
        "remaining_missing = df.isnull().sum().sum()\n",
        "print(\"\\nRemaining missing values:\", remaining_missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV6DheVYoD40",
        "outputId": "036d36ad-d498-4486-e14b-3a6f1f0be14c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Remaining missing values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying descriptive statistics\n",
        "descriptive_statistics=df.describe()\n",
        "print(descriptive_statistics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbJJLu2EoFqs",
        "outputId": "8f694ade-d946-4e58-de52-b27b2b5fbab3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                id          NH4         BSK5    Suspended           O2  \\\n",
            "count  2861.000000  2861.000000  2861.000000  2861.000000  2861.000000   \n",
            "mean     12.397064     0.758734     4.316182    12.931905     9.508902   \n",
            "std       6.084226     2.484943     2.973477    16.496758     4.425937   \n",
            "min       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
            "25%       8.000000     0.080000     2.160000     6.000000     7.100000   \n",
            "50%      14.000000     0.220000     3.800000    10.000000     9.000000   \n",
            "75%      16.000000     0.500000     5.800000    14.800000    11.520000   \n",
            "max      22.000000    39.427000    50.900000   595.000000    90.000000   \n",
            "\n",
            "               NO3          NO2          SO4          PO4           CL  \n",
            "count  2861.000000  2861.000000  2861.000000  2861.000000  2861.000000  \n",
            "mean      4.316846     0.246128    59.362313     0.418626    93.731991  \n",
            "std       6.879985     2.181631    95.751698     0.767541   391.118021  \n",
            "min       0.000000     0.000000     0.000000     0.000000     0.020000  \n",
            "25%       1.390000     0.030000    27.200000     0.130000    26.800000  \n",
            "50%       2.800000     0.059000    38.100000     0.278000    34.100000  \n",
            "75%       5.580000     0.129000    63.700000     0.468000    46.330000  \n",
            "max     133.400000   109.000000  3573.400000    13.879000  5615.280000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the independent variables (features)\n",
        "independent_variables = ['id','BSK5','Suspended','O2','NO3','SO4','PO4','CL']\n",
        "# Define the dependent variable (target)\n",
        "dependent_variable = 'NH4'\n",
        "# Split the data into features (X) and target (y)\n",
        "X = df[independent_variables]\n",
        "y = df[dependent_variable]\n",
        "# Split the data into training and testing sets\n",
        "# Specify the test_size and random_state for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training data - Features shape:\", X_train.shape)\n",
        "print(\"Testing data - Features shape:\", X_test.shape)\n",
        "print(\"Training data - Target shape:\", y_train.shape)\n",
        "print(\"Testing data - Target shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MqLzs5LoIEu",
        "outputId": "cda55985-4450-4ad6-af43-c4ad740734c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data - Features shape: (2288, 8)\n",
            "Testing data - Features shape: (573, 8)\n",
            "Training data - Target shape: (2288,)\n",
            "Testing data - Target shape: (573,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train a GradientBoostingRegressor model\n",
        "model1 = GradientBoostingRegressor(random_state=42)\n",
        "model1.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the training and testing data\n",
        "y_train_pred = model1.predict(X_train_scaled)\n",
        "y_test_pred = model1.predict(X_test_scaled)\n",
        "\n",
        "# Calculate and print mean squared error for the training dataset\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "print(\"Training Mean Squared Error:\", train_mse)\n",
        "\n",
        "# Calculate and print mean squared error for the testing dataset\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "print(\"Testing Mean Squared Error:\", test_mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra7j1cG8oKJe",
        "outputId": "af0a7ee8-3e01-46b8-92be-309af65a6996"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Mean Squared Error: 0.4009048958366622\n",
            "Testing Mean Squared Error: 3.5990540023021964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "model2 = SVR(kernel='linear', C=1.0)\n",
        "model2.fit(X_train_scaled, y_train)\n",
        "y_pred = model2.predict(X_test_scaled)\n",
        "mse2 = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse2}\")\n",
        "print(f\"R-squared:{r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8SPz6GhoMgM",
        "outputId": "2b6c77a9-2c7c-464a-ccef-4627b4d4813b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 8.499469507976594\n",
            "R-squared:0.15116278329266986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Sample data and target values (replace with your data)\n",
        "# Ensure that your data and target are properly preprocessed and in the right format\n",
        "data = np.random.rand(100, 10)  # Example input data\n",
        "target = np.random.rand(100)     # Example target values\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "# Standardize the input data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Reshape the data for LSTM (number of samples, number of time steps, number of features)\n",
        "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
        "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        "# Create an LSTM model\n",
        "model3 = Sequential()\n",
        "model3.add(LSTM(50, input_shape=(1, X_train_scaled.shape[1])))\n",
        "model3.add(Dense(1))  # Single output neuron for regression\n",
        "# Compile the model\n",
        "model3.compile(loss='mean_squared_error', optimizer='adam')\n",
        "# Train the model\n",
        "model3.fit(X_train_reshaped, y_train, epochs=50, batch_size=1)\n",
        "# Make predictions on the test set\n",
        "y_pred = model3.predict(X_test_reshaped)\n",
        "# Calculate the Mean Squared Error (MSE) as the accuracy metric\n",
        "mse3 = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ9OkRo3oOZv",
        "outputId": "f6964827-8b0b-4b2e-d3ca-1d69214ae265"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "80/80 [==============================] - 2s 2ms/step - loss: 0.2348\n",
            "Epoch 2/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1212\n",
            "Epoch 3/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0801\n",
            "Epoch 4/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0704\n",
            "Epoch 5/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0689\n",
            "Epoch 6/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0668\n",
            "Epoch 7/50\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0649\n",
            "Epoch 8/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0634\n",
            "Epoch 9/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0622\n",
            "Epoch 10/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0595\n",
            "Epoch 11/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0584\n",
            "Epoch 12/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0568\n",
            "Epoch 13/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0564\n",
            "Epoch 14/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0544\n",
            "Epoch 15/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0543\n",
            "Epoch 16/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0538\n",
            "Epoch 17/50\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0513\n",
            "Epoch 18/50\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.0498\n",
            "Epoch 19/50\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0481\n",
            "Epoch 20/50\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.0464\n",
            "Epoch 21/50\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0458\n",
            "Epoch 22/50\n",
            "80/80 [==============================] - 1s 6ms/step - loss: 0.0435\n",
            "Epoch 23/50\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.0441\n",
            "Epoch 24/50\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0420\n",
            "Epoch 25/50\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.0399\n",
            "Epoch 26/50\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.0393\n",
            "Epoch 27/50\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.0384\n",
            "Epoch 28/50\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.0369\n",
            "Epoch 29/50\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0359\n",
            "Epoch 30/50\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0346\n",
            "Epoch 31/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0325\n",
            "Epoch 32/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0313\n",
            "Epoch 33/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0316\n",
            "Epoch 34/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0300\n",
            "Epoch 35/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0282\n",
            "Epoch 36/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0269\n",
            "Epoch 37/50\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0269\n",
            "Epoch 38/50\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0259\n",
            "Epoch 39/50\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0255\n",
            "Epoch 40/50\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.0234\n",
            "Epoch 41/50\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.0227\n",
            "Epoch 42/50\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.0218\n",
            "Epoch 43/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0213\n",
            "Epoch 44/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0204\n",
            "Epoch 45/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0198\n",
            "Epoch 46/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0198\n",
            "Epoch 47/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0183\n",
            "Epoch 48/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0170\n",
            "Epoch 49/50\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.0165\n",
            "Epoch 50/50\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.0159\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Mean Squared Error (MSE): 0.22580608677306002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load your data and define X_train, y_train, X_test, and y_test\n",
        "\n",
        "# Example data loading and splitting\n",
        "# X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the MLP Regressor model\n",
        "model4 = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', random_state=42)\n",
        "model4.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model4.predict(X_test_scaled)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse4 = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFL_x45toRKs",
        "outputId": "beeb79e7-3a13-45e6-95ae-71b92f235eb9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.1545672967781545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_values={\"GradientBoostingRegressor\": test_mse,\n",
        "            \"SVR\":mse2,\n",
        "            \"LSTM\":mse3,\n",
        "            \"MLP Regression\":mse4}\n",
        "print(\"MSE Value: \",mse_values)\n",
        "\n",
        "best_model=min(mse_values,key=mse_values.get)\n",
        "for model,mse in mse_values.items():\n",
        "  print(f\"{model}:{mse}\")\n",
        "print(f\"The best model is {best_model} with MSE {mse_values[best_model]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2a-lsRWoVCS",
        "outputId": "1580ae22-07f7-45f9-cf9f-f75a8f4a6ef7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE Value:  {'GradientBoostingRegressor': 3.5990540023021964, 'SVR': 8.499469507976594, 'LSTM': 0.22580608677306002, 'MLP Regression': 0.1545672967781545}\n",
            "GradientBoostingRegressor:3.5990540023021964\n",
            "SVR:8.499469507976594\n",
            "LSTM:0.22580608677306002\n",
            "MLP Regression:0.1545672967781545\n",
            "The best model is MLP Regression with MSE 0.1545672967781545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2FkgeVboYO2",
        "outputId": "126d14ec-6e2a-4263-b57b-a6f30f74fb24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model4, 'model4.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k3u56ypoaCr",
        "outputId": "da206fa7-e413-4df4-9b39-593f46379ff6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model4.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(scaler, 'standard_scaler.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyaiYufEpNCM",
        "outputId": "d64a37d4-8971-4f25-965d-2d84c9092f4f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['standard_scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}